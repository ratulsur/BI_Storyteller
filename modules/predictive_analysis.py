"""
Predictive Analytics Module
Performs predictive analysis using basic statistical methods
"""

import json
import random
from typing import List, Dict, Any, Tuple
from collections import Counter, defaultdict
import statistics


class PredictiveAnalyzer:
    """Perform predictive analytics on survey data"""
    
    def __init__(self):
        self.models = {}
        self.feature_importance = {}
        self.predictions = {}
    
    def analyze(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Perform comprehensive predictive analysis"""
        print("ðŸ”® Running predictive analytics...")
        
        results = {
            'classification_models': {},
            'feature_importance': {},
            'predictions': {},
            'metrics': {},
            'insights': [],
            'recommendations': []
        }
        
        # Prepare data for analysis
        processed_data = self._prepare_data_for_modeling(data)
        
        if not processed_data['features'] or not processed_data['targets']:
            return {
                'error': 'Insufficient data for predictive analysis',
                'metrics': {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}
            }
        
        # Identify potential target variables (satisfaction, ratings, etc.)
        target_variables = self._identify_target_variables(processed_data)
        
        # Perform analysis for each target variable
        for target_var in target_variables:
            model_results = self._build_prediction_model(processed_data, target_var)
            results['classification_models'][target_var] = model_results
            
            # Calculate feature importance
            importance = self._calculate_feature_importance(processed_data, target_var)
            results['feature_importance'][target_var] = importance
        
        # Generate overall metrics
        results['metrics'] = self._calculate_overall_metrics(results['classification_models'])
        
        # Make predictions for new scenarios
        results['predictions'] = self._generate_predictions(processed_data, target_variables)
        
        # Generate insights and recommendations
        results['insights'] = self._generate_predictive_insights(results)
        results['recommendations'] = self._generate_recommendations(results)
        
        return results
    
    def _prepare_data_for_modeling(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Prepare and structure data for predictive modeling"""
        features = defaultdict(list)
        targets = defaultdict(list)
        feature_types = {}
        
        # Extract features and potential targets
        for response in data:
            answers = response.get('answers', {})
            response_features = {}
            response_targets = {}
            
            for q_id, answer_data in answers.items():
                question = answer_data.get('question', '').lower()
                answer = answer_data.get('answer', '')
                category = answer_data.get('category', 'general')
                question_type = answer_data.get('question_type', 'unknown')
                
                if not answer:
                    continue
                
                # Classify as feature or target
                if category in ['satisfaction', 'rating']:
                    # These are potential targets for prediction
                    encoded_answer = self._encode_categorical_target(answer)
                    response_targets[q_id] = encoded_answer
                    targets[q_id].append(encoded_answer)
                
                elif category in ['demographic', 'behavioral', 'preference']:
                    # These are features for prediction
                    encoded_answer = self._encode_feature(answer, question_type)
                    response_features[q_id] = encoded_answer
                    features[q_id].append(encoded_answer)
                    feature_types[q_id] = question_type
            
            # Store the complete response for later use
            if response_features:
                for feature_id, feature_value in response_features.items():
                    if feature_id not in features:
                        features[feature_id] = []
                    # Ensure we have the right index alignment
                    while len(features[feature_id]) < len(data):
                        if response in data[:data.index(response) + 1]:
                            break
        
        return {
            'features': dict(features),
            'targets': dict(targets),
            'feature_types': feature_types,
            'raw_data': data
        }
    
    def _encode_categorical_target(self, answer: str) -> int:
        """Encode categorical target variable to numeric"""
        satisfaction_mapping = {
            'Very Satisfied': 5, 'Satisfied': 4, 'Neutral': 3,
            'Dissatisfied': 2, 'Very Dissatisfied': 1,
            'Excellent': 5, 'Good': 4, 'Average': 3,
            'Poor': 2, 'Very Poor': 1
        }
        
        return satisfaction_mapping.get(str(answer), 3)  # Default to neutral
    
    def _encode_feature(self, answer: str, question_type: str) -> float:
        """Encode feature variable to numeric"""
        if question_type == 'MCQ':
            # Create mappings for common categorical variables
            age_mapping = {'18-25': 1, '26-35': 2, '36-45': 3, '46-55': 4, '56-65': 5, '65+': 6}
            income_mapping = {'<$25k': 1, '$25k-$50k': 2, '$50k-$75k': 3, '$75k-$100k': 4, '>$100k': 5}
            frequency_mapping = {'Never': 1, 'Rarely': 2, 'Monthly': 3, 'Weekly': 4, 'Daily': 5}
            education_mapping = {'High School': 1, "Bachelor's": 2, "Master's": 3, 'PhD': 4, 'Other': 2}
            
            answer_str = str(answer)
            
            # Try different mappings
            for mapping in [age_mapping, income_mapping, frequency_mapping, education_mapping]:
                if answer_str in mapping:
                    return mapping[answer_str]
            
            # Binary encoding for gender and other categories
            if answer_str.lower() in ['male', 'female']:
                return 1 if answer_str.lower() == 'male' else 0
            
            # Hash-based encoding for other categorical values
            return hash(answer_str) % 10 + 1  # Map to 1-10 range
        
        else:  # Descriptive
            # Simple text feature: length-based encoding
            return min(len(str(answer)) / 10, 10)  # Normalize to 0-10 range
    
    def _identify_target_variables(self, processed_data: Dict[str, Any]) -> List[str]:
        """Identify suitable target variables for prediction"""
        targets = processed_data.get('targets', {})
        
        # Filter targets with sufficient variation
        suitable_targets = []
        
        for target_id, target_values in targets.items():
            if len(set(target_values)) >= 2 and len(target_values) >= 10:
                # Has variation and sufficient data
                suitable_targets.append(target_id)
        
        return suitable_targets
    
    def _build_prediction_model(self, processed_data: Dict[str, Any], 
                              target_var: str) -> Dict[str, Any]:
        """Build a simple prediction model using basic statistical methods"""
        features = processed_data.get('features', {})
        targets = processed_data.get('targets', {})
        
        if target_var not in targets:
            return {'error': f'Target variable {target_var} not found'}
        
        target_values = targets[target_var]
        
        # Simple correlation-based model
        feature_correlations = {}
        
        for feature_id, feature_values in features.items():
            # Align feature and target values
            min_length = min(len(feature_values), len(target_values))
            if min_length < 5:
                continue
            
            aligned_features = feature_values[:min_length]
            aligned_targets = target_values[:min_length]
            
            # Calculate simple correlation
            correlation = self._calculate_simple_correlation(aligned_features, aligned_targets)
            feature_correlations[feature_id] = correlation
        
        # Create prediction rules based on correlations
        prediction_rules = {}
        for feature_id, correlation in feature_correlations.items():
            if abs(correlation) > 0.1:  # Only significant correlations
                prediction_rules[feature_id] = {
                    'correlation': correlation,
                    'weight': correlation,
                    'feature_type': processed_data.get('feature_types', {}).get(feature_id, 'unknown')
                }
        
        # Evaluate model performance
        accuracy = self._evaluate_model_accuracy(features, targets[target_var], prediction_rules)
        
        return {
            'target_variable': target_var,
            'prediction_rules': prediction_rules,
            'feature_correlations': feature_correlations,
            'model_accuracy': accuracy,
            'training_samples': len(target_values),
            'feature_count': len([f for f in feature_correlations.values() if abs(f) > 0.1])
        }
    
    def _calculate_simple_correlation(self, feature_values: List[float], 
                                    target_values: List[int]) -> float:
        """Calculate simple correlation coefficient"""
        if len(feature_values) != len(target_values) or len(feature_values) < 2:
            return 0
        
        try:
            # Simple correlation calculation
            n = len(feature_values)
            
            sum_f = sum(feature_values)
            sum_t = sum(target_values)
            sum_ft = sum(f * t for f, t in zip(feature_values, target_values))
            sum_f2 = sum(f * f for f in feature_values)
            sum_t2 = sum(t * t for t in target_values)
            
            numerator = n * sum_ft - sum_f * sum_t
            denominator = ((n * sum_f2 - sum_f * sum_f) * (n * sum_t2 - sum_t * sum_t)) ** 0.5
            
            if denominator == 0:
                return 0
            
            correlation = numerator / denominator
            return max(-1, min(1, correlation))  # Clamp to [-1, 1]
            
        except (ZeroDivisionError, ValueError):
            return 0
    
    def _evaluate_model_accuracy(self, features: Dict[str, List[float]], 
                                targets: List[int], 
                                prediction_rules: Dict[str, Any]) -> float:
        """Evaluate model accuracy using simple prediction"""
        if not prediction_rules or not targets:
            return 0
        
        correct_predictions = 0
        total_predictions = 0
        
        # Make predictions for each data point
        for i in range(len(targets)):
            predicted_value = self._make_simple_prediction(features, i, prediction_rules)
            actual_value = targets[i]
            
            # Allow for Â±1 tolerance in predictions (since we're predicting satisfaction scores)
            if abs(predicted_value - actual_value) <= 1:
                correct_predictions += 1
            
            total_predictions += 1
        
        return correct_predictions / max(total_predictions, 1)
    
    def _make_simple_prediction(self, features: Dict[str, List[float]], 
                              index: int, 
                              prediction_rules: Dict[str, Any]) -> float:
        """Make a simple prediction using weighted features"""
        weighted_sum = 0
        total_weight = 0
        
        for feature_id, rule in prediction_rules.items():
            if feature_id in features and index < len(features[feature_id]):
                feature_value = features[feature_id][index]
                weight = abs(rule['weight'])
                
                weighted_sum += feature_value * weight
                total_weight += weight
        
        if total_weight == 0:
            return 3  # Default to neutral
        
        # Normalize to 1-5 scale (satisfaction scale)
        predicted_value = weighted_sum / total_weight
        
        # Map to satisfaction scale
        return max(1, min(5, predicted_value))
    
    def _calculate_feature_importance(self, processed_data: Dict[str, Any], 
                                    target_var: str) -> Dict[str, float]:
        """Calculate feature importance scores"""
        features = processed_data.get('features', {})
        targets = processed_data.get('targets', {})
        
        if target_var not in targets:
            return {}
        
        target_values = targets[target_var]
        importance_scores = {}
        
        for feature_id, feature_values in features.items():
            # Calculate importance based on correlation and variance
            min_length = min(len(feature_values), len(target_values))
            if min_length < 5:
                continue
            
            aligned_features = feature_values[:min_length]
            aligned_targets = target_values[:min_length]
            
            # Correlation-based importance
            correlation = abs(self._calculate_simple_correlation(aligned_features, aligned_targets))
            
            # Variance-based importance (features with more variance are potentially more important)
            try:
                feature_variance = statistics.variance(aligned_features) if len(aligned_features) > 1 else 0
                normalized_variance = min(feature_variance / 10, 1)  # Normalize
            except:
                normalized_variance = 0
            
            # Combined importance score
            importance = (correlation * 0.7) + (normalized_variance * 0.3)
            importance_scores[feature_id] = importance
        
        # Normalize importance scores to percentages
        total_importance = sum(importance_scores.values())
        if total_importance > 0:
            importance_scores = {k: (v / total_importance) * 100 
                               for k, v in importance_scores.items()}
        
        return dict(sorted(importance_scores.items(), key=lambda x: x[1], reverse=True))
    
    def _calculate_overall_metrics(self, classification_models: Dict[str, Any]) -> Dict[str, float]:
        """Calculate overall model performance metrics"""
        if not classification_models:
            return {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}
        
        accuracies = []
        feature_counts = []
        
        for model_id, model_data in classification_models.items():
            if 'model_accuracy' in model_data:
                accuracies.append(model_data['model_accuracy'])
            if 'feature_count' in model_data:
                feature_counts.append(model_data['feature_count'])
        
        avg_accuracy = statistics.mean(accuracies) if accuracies else 0
        
        # Simplified metrics (in real implementation, calculate actual precision/recall)
        precision = avg_accuracy * 0.9  # Assume precision is slightly lower than accuracy
        recall = avg_accuracy * 0.95    # Assume recall is close to accuracy
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        return {
            'accuracy': avg_accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'avg_features_used': statistics.mean(feature_counts) if feature_counts else 0
        }
    
    def _generate_predictions(self, processed_data: Dict[str, Any], 
                            target_variables: List[str]) -> Dict[str, Any]:
        """Generate sample predictions for different scenarios"""
        predictions = {}
        
        for target_var in target_variables:
            # Create sample scenarios for prediction
            scenarios = self._create_sample_scenarios(processed_data)
            
            predictions[target_var] = {
                'scenarios': [],
                'confidence_intervals': {}
            }
            
            for scenario_name, scenario_features in scenarios.items():
                # Make prediction for this scenario (simplified)
                predicted_value = self._predict_scenario(scenario_features, target_var)
                
                predictions[target_var]['scenarios'].append({
                    'scenario': scenario_name,
                    'features': scenario_features,
                    'predicted_value': predicted_value,
                    'confidence': random.uniform(0.6, 0.9)  # Simulated confidence
                })
        
        return predictions
    
    def _create_sample_scenarios(self, processed_data: Dict[str, Any]) -> Dict[str, Dict[str, float]]:
        """Create sample scenarios for prediction"""
        features = processed_data.get('features', {})
        
        scenarios = {
            'High Value Customer': {},
            'Average Customer': {},
            'At-Risk Customer': {}
        }
        
        # Create scenarios based on feature ranges
        for feature_id, feature_values in features.items():
            if not feature_values:
                continue
                
            min_val = min(feature_values)
            max_val = max(feature_values)
            avg_val = sum(feature_values) / len(feature_values)
            
            scenarios['High Value Customer'][feature_id] = max_val * 0.8 + min_val * 0.2
            scenarios['Average Customer'][feature_id] = avg_val
            scenarios['At-Risk Customer'][feature_id] = min_val * 0.8 + max_val * 0.2
        
        return scenarios
    
    def _predict_scenario(self, scenario_features: Dict[str, float], target_var: str) -> float:
        """Predict target value for a given scenario"""
        # Simple prediction based on weighted average of features
        # In real implementation, use the trained model
        
        total_weight = 0
        weighted_sum = 0
        
        for feature_id, feature_value in scenario_features.items():
            # Use simple heuristics for prediction
            weight = 1.0  # Equal weights for simplicity
            weighted_sum += feature_value * weight
            total_weight += weight
        
        if total_weight == 0:
            return 3.0  # Default neutral
        
        predicted = weighted_sum / total_weight
        return max(1.0, min(5.0, predicted))  # Clamp to satisfaction scale
    
    def _generate_predictive_insights(self, results: Dict[str, Any]) -> List[str]:
        """Generate insights from predictive analysis"""
        insights = []
        
        metrics = results.get('metrics', {})
        accuracy = metrics.get('accuracy', 0)
        
        insights.append(f"Model accuracy: {accuracy:.1%}")
        
        if accuracy > 0.7:
            insights.append("High predictive accuracy achieved - models are reliable for decision-making")
        elif accuracy > 0.5:
            insights.append("Moderate predictive accuracy - models show useful patterns but need refinement")
        else:
            insights.append("Low predictive accuracy - more data or features needed for better predictions")
        
        # Feature importance insights
        feature_importance = results.get('feature_importance', {})
        if feature_importance:
            for target_var, importance_dict in feature_importance.items():
                if importance_dict:
                    top_feature = max(importance_dict.items(), key=lambda x: x[1])
                    insights.append(f"Most predictive feature for {target_var}: {top_feature[0]} ({top_feature[1]:.1f}% importance)")
        
        # Classification model insights
        classification_models = results.get('classification_models', {})
        if classification_models:
            insights.append(f"Built {len(classification_models)} prediction models")
            
            total_features = sum(model.get('feature_count', 0) for model in classification_models.values())
            if total_features > 0:
                insights.append(f"Using {total_features} predictive features across all models")
        
        return insights
    
    def _generate_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """Generate actionable recommendations from analysis"""
        recommendations = []
        
        metrics = results.get('metrics', {})
        accuracy = metrics.get('accuracy', 0)
        
        # Model improvement recommendations
        if accuracy < 0.6:
            recommendations.append("Collect more diverse data to improve model accuracy")
            recommendations.append("Consider additional feature engineering to capture complex patterns")
        
        # Feature recommendations
        feature_importance = results.get('feature_importance', {})
        for target_var, importance_dict in feature_importance.items():
            if importance_dict:
                # Find low-importance features
                low_importance = [f for f, score in importance_dict.items() if score < 5]
                if low_importance:
                    recommendations.append(f"Consider removing low-impact features: {', '.join(low_importance[:3])}")
                
                # Recommend focusing on high-importance features
                high_importance = [f for f, score in importance_dict.items() if score > 20]
                if high_importance:
                    recommendations.append(f"Focus on high-impact features: {', '.join(high_importance[:3])}")
        
        # Business recommendations
        predictions = results.get('predictions', {})
        for target_var, prediction_data in predictions.items():
            scenarios = prediction_data.get('scenarios', [])
            
            if scenarios:
                # Find best and worst scenarios
                scenario_values = [(s['scenario'], s['predicted_value']) for s in scenarios]
                
                if scenario_values:
                    best_scenario = max(scenario_values, key=lambda x: x[1])
                    worst_scenario = min(scenario_values, key=lambda x: x[1])
                    
                    recommendations.append(f"Target customers similar to '{best_scenario[0]}' profile for best outcomes")
                    recommendations.append(f"Implement interventions for '{worst_scenario[0]}' profile to prevent churn")
        
        # Data collection recommendations
        if len(results.get('classification_models', {})) < 3:
            recommendations.append("Collect data on additional satisfaction/outcome metrics for comprehensive analysis")
        
        avg_features_used = metrics.get('avg_features_used', 0)
        if avg_features_used < 5:
            recommendations.append("Expand feature set to include more behavioral and contextual variables")
        
        return recommendations